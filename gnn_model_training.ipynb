{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Here we will build and train our model using the graphs we previously built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import dgl\n",
    "import scipy\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dgl.data.utils import save_graphs, load_graphs, split_dataset\n",
    "\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our graphs from before\n",
    "glist, label_dict = load_graphs(\"./data_final.bin\")\n",
    "unsup_graph, sup_graph = glist[0], glist[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix problem where we have a label of -1 to represent the missing class\n",
    "tempLabels = sup_graph.ndata['label']\n",
    "\n",
    "#something weird - no labels from original data had class 8??? --> map our -1 class to 8 so it works with cross-entropy loss\n",
    "tempLabels[tempLabels==-1] = 8\n",
    "\n",
    "sup_graph.ndata['label'] = tempLabels\n",
    "unsup_graph.ndata['label'] = tempLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add self loops to both graphs\n",
    "sup_graph = sup_graph.add_self_loop()\n",
    "unsup_graph = unsup_graph.add_self_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tug57226/.local/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: DGLGraph.__len__ is deprecated.Please directly call DGLGraph.number_of_nodes.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#split data into train,test,val\n",
    "sup_split = split_dataset(sup_graph, shuffle=True, random_state=10)\n",
    "unsup_split = split_dataset(sup_graph, shuffle=True, random_state=10)\n",
    "\n",
    "#extract the splits\n",
    "sup_train, sup_val, sup_test = sup_split[0], sup_split[1], sup_split[2]\n",
    "unsup_train, unsup_val, unsup_test = unsup_split[0], unsup_split[1], unsup_split[2]\n",
    "\n",
    "#convert the index based representation into boolean masks for the graphs\n",
    "n = sup_graph.number_of_nodes() #total num nodes in each graph\n",
    "train_mask, val_mask, test_mask = np.zeros(n, dtype=bool), np.zeros(n, dtype=bool), np.zeros(n, dtype=bool) #create empty arrays for train/val/test\n",
    "\n",
    "#populate our boolean masks\n",
    "train_mask[sup_train.indices] = True \n",
    "val_mask[sup_val.indices] = True\n",
    "test_mask[sup_test.indices] = True\n",
    "\n",
    "#embed these masks into our graph\n",
    "sup_graph.ndata['train_mask'], sup_graph.ndata['val_mask'], sup_graph.ndata['test_mask'] = th.tensor(train_mask, dtype=bool), th.tensor(val_mask, dtype=bool), th.tensor(test_mask, dtype=bool)\n",
    "unsup_graph.ndata['train_mask'], unsup_graph.ndata['val_mask'], unsup_graph.ndata['test_mask'] = th.tensor(train_mask), th.tensor(val_mask), th.tensor(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sup_split[0].indices == unsup_split[0].indices) == len(sup_split[0]) #confirm we have the same nodes in both splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract and store information from each graph\n",
    "\n",
    "#sup\n",
    "sup_node_features = sup_graph.ndata['features']\n",
    "sup_node_labels = sup_graph.ndata['label']\n",
    "\n",
    "#unsup\n",
    "unsup_node_features = unsup_graph.ndata['features']\n",
    "unsup_node_labels = unsup_graph.ndata['label']\n",
    "\n",
    "\n",
    "#general graph characteristics - doesn't matter which graph\n",
    "train_mask = sup_graph.ndata['train_mask']\n",
    "valid_mask = sup_graph.ndata['val_mask']\n",
    "test_mask = sup_graph.ndata['test_mask']\n",
    "n_features = sup_node_features.shape[1]\n",
    "n_labels = int(sup_node_labels.max().item() + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple base GraphSage model\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats1, hid_feats2, out_feats):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(dglnn.SAGEConv(\n",
    "            in_feats=in_feats, out_feats = hid_feats1, aggregator_type='pool', activation= F.relu))\n",
    "        self.layers.append(dglnn.SAGEConv(\n",
    "            in_feats=hid_feats1, out_feats = hid_feats2, aggregator_type='mean', activation= F.relu))\n",
    "        self.layers.append(nn.Linear(in_features=hid_feats2, out_features = out_feats))\n",
    "        self.layers.append(nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        h = inputs\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            # inputs are features of nodes\n",
    "            #different cases for graph layers and fully connected layers\n",
    "            if i<=1:\n",
    "                h = layer(graph, h)\n",
    "            else:\n",
    "                h = layer(h)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate model\n",
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = th.max(logits, dim=1)\n",
    "        correct = th.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 1/10 [13:21<2:00:14, 801.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.020709037780762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 2/10 [25:31<1:44:00, 780.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.84567403793335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 3/10 [37:47<1:29:28, 766.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.841334342956543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [50:14<1:16:06, 761.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.841331958770752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 5/10 [1:02:59<1:03:30, 762.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.841331958770752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 6/10 [1:17:12<52:37, 789.33s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.841331958770752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 7/10 [1:31:25<40:25, 808.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.841331958770752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 8/10 [1:45:24<27:15, 817.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.841331958770752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 9/10 [1:59:23<13:43, 823.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.841331958770752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 10/10 [2:15:55<00:00, 874.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.841331958770752\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "model = SAGE(in_feats=n_features, hid_feats1=256, hid_feats2=128, out_feats=n_labels)\n",
    "opt = th.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in tqdm(range(10)):\n",
    "    model.train()\n",
    "    \n",
    "    # forward propagation by using all nodes - extract separate logits\n",
    "    sup_logits = model(sup_graph, sup_node_features)\n",
    "    unsup_logits = model(unsup_graph, unsup_node_features)\n",
    "    \n",
    "    # compute losses\n",
    "    sup_loss = F.cross_entropy(sup_logits[train_mask], sup_node_labels[train_mask])\n",
    "    unsup_loss = F.cross_entropy(unsup_logits[train_mask], unsup_node_labels[train_mask])\n",
    "    \n",
    "    # compute validation accuracy\n",
    "    sup_acc = evaluate(model, sup_graph, sup_node_features, sup_node_labels, valid_mask)\n",
    "    unsup_acc = evaluate(model, unsup_graph, unsup_node_features, unsup_node_labels, valid_mask)\n",
    "    \n",
    "    #add additional term which is average euclidean distance between logits\n",
    "    additional_term = th.dist(sup_logits, unsup_logits,2)/n\n",
    "    \n",
    "    #get total loss\n",
    "    loss = sup_loss + unsup_loss + additional_term\n",
    "    \n",
    "    # backward propagation\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss.item())\n",
    "\n",
    "    # Save model\n",
    "    th.save(model.state_dict(), f'./models/model{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.596098944615328"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy: 59.6%\n",
    "#Loss: 7.84 - stable after 3 epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
